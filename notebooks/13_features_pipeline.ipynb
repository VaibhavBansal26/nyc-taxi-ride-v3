{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "import src.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-06 19:01:29.152912\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "current_date = pd.to_datetime(datetime.utcnow())\n",
    "print(f\"{current_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "current_date = pd.to_datetime(datetime.now(timezone.utc)).floor(\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2025-03-06T19:00:00.000000000')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_date.to_datetime64()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_data_to = current_date\n",
    "fetch_data_from = current_date - timedelta(weeks=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2025-03-06 19:00:00+0000', tz='UTC')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_data_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-03-07 19:00:00+0000', tz='UTC')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_data_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from typing import Union\n",
    "import pandas as pd\n",
    "from src.data_utils import load_and_process_taxi_data\n",
    "\n",
    "def fetch_batch_raw_data(from_date: Union[datetime, str], to_date: Union[datetime, str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simulate production data by sampling historical data from 52 weeks ago (i.e., 1 year).\n",
    "\n",
    "    Args:\n",
    "        from_date (datetime or str): The start date for the data batch.\n",
    "        to_date (datetime or str): The end date for the data batch.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the simulated production data.\n",
    "    \"\"\"\n",
    "    # Convert string inputs to datetime if necessary\n",
    "    if isinstance(from_date, str):\n",
    "        from_date = datetime.fromisoformat(from_date)\n",
    "    if isinstance(to_date, str):\n",
    "        to_date = datetime.fromisoformat(to_date)\n",
    "\n",
    "    # Validate input dates\n",
    "    if not isinstance(from_date, datetime) or not isinstance(to_date, datetime):\n",
    "        raise ValueError(\"Both 'from_date' and 'to_date' must be datetime objects or valid ISO format strings.\")\n",
    "    if from_date >= to_date:\n",
    "        raise ValueError(\"'from_date' must be earlier than 'to_date'.\")\n",
    "\n",
    "    # Shift dates back by 52 weeks (1 year)\n",
    "    historical_from_date = from_date - timedelta(weeks=52)\n",
    "    historical_to_date = to_date - timedelta(weeks=52)\n",
    "    # - timedelta(weeks=52)\n",
    "\n",
    "    print(historical_from_date)\n",
    "    print(historical_to_date)\n",
    "\n",
    "    # Load and filter data for the historical period\n",
    "    rides_from = load_and_process_taxi_data(year=historical_from_date.year)\n",
    "    rides_from = rides_from[rides_from.pickup_datetime >= historical_from_date.to_datetime64()]\n",
    "\n",
    "    if historical_to_date.month != historical_from_date.month:\n",
    "        rides_to = load_and_process_taxi_data(year=historical_to_date.year, months=[historical_to_date.month])\n",
    "        rides_to = rides_to[rides_to.pickup_datetime < historical_to_date.to_datetime64()]\n",
    "        # Combine the filtered data\n",
    "        rides = pd.concat([rides_from, rides_to], ignore_index=True)\n",
    "    else:\n",
    "        rides = rides_from\n",
    "    # Shift the data forward by 52 weeks to simulate recent data\n",
    "    rides['pickup_datetime'] += timedelta(weeks=52)\n",
    "    print(rides['pickup_datetime'])\n",
    "\n",
    "    # Sort the data for consistency\n",
    "    rides.sort_values(by=['pickup_location_id', 'pickup_datetime'], inplace=True)\n",
    "\n",
    "    return rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-09 19:00:00+00:00\n",
      "2024-03-07 19:00:00+00:00\n",
      "File already exists for 2023-01.\n",
      "Loading data for 2023-01...\n",
      "Total records: 3,066,766\n",
      "Valid records: 2,993,140\n",
      "Records dropped: 73,626 (2.40%)\n",
      "Successfully processed data for 2023-01.\n",
      "File already exists for 2023-02.\n",
      "Loading data for 2023-02...\n",
      "Total records: 2,913,955\n",
      "Valid records: 2,845,058\n",
      "Records dropped: 68,897 (2.36%)\n",
      "Successfully processed data for 2023-02.\n",
      "File already exists for 2023-03.\n",
      "Loading data for 2023-03...\n",
      "Total records: 3,403,766\n",
      "Valid records: 3,331,705\n",
      "Records dropped: 72,061 (2.12%)\n",
      "Successfully processed data for 2023-03.\n",
      "File already exists for 2023-04.\n",
      "Loading data for 2023-04...\n",
      "Total records: 3,288,250\n",
      "Valid records: 3,214,922\n",
      "Records dropped: 73,328 (2.23%)\n",
      "Successfully processed data for 2023-04.\n",
      "File already exists for 2023-05.\n",
      "Loading data for 2023-05...\n",
      "Total records: 3,513,649\n",
      "Valid records: 3,435,875\n",
      "Records dropped: 77,774 (2.21%)\n",
      "Successfully processed data for 2023-05.\n",
      "File already exists for 2023-06.\n",
      "Loading data for 2023-06...\n",
      "Total records: 3,307,234\n",
      "Valid records: 3,233,969\n",
      "Records dropped: 73,265 (2.22%)\n",
      "Successfully processed data for 2023-06.\n",
      "File already exists for 2023-07.\n",
      "Loading data for 2023-07...\n",
      "Total records: 2,907,108\n",
      "Valid records: 2,838,637\n",
      "Records dropped: 68,471 (2.36%)\n",
      "Successfully processed data for 2023-07.\n",
      "File already exists for 2023-08.\n",
      "Loading data for 2023-08...\n",
      "Total records: 2,824,209\n",
      "Valid records: 2,758,739\n",
      "Records dropped: 65,470 (2.32%)\n",
      "Successfully processed data for 2023-08.\n",
      "File already exists for 2023-09.\n",
      "Loading data for 2023-09...\n",
      "Total records: 2,846,722\n",
      "Valid records: 2,782,920\n",
      "Records dropped: 63,802 (2.24%)\n",
      "Successfully processed data for 2023-09.\n",
      "File already exists for 2023-10.\n",
      "Loading data for 2023-10...\n",
      "Total records: 3,522,285\n",
      "Valid records: 3,446,406\n",
      "Records dropped: 75,879 (2.15%)\n",
      "Successfully processed data for 2023-10.\n",
      "File already exists for 2023-11.\n",
      "Loading data for 2023-11...\n",
      "Total records: 3,339,715\n",
      "Valid records: 3,267,940\n",
      "Records dropped: 71,775 (2.15%)\n",
      "Successfully processed data for 2023-11.\n",
      "File already exists for 2023-12.\n",
      "Loading data for 2023-12...\n",
      "Total records: 3,376,567\n",
      "Valid records: 3,313,957\n",
      "Records dropped: 62,610 (1.85%)\n",
      "Successfully processed data for 2023-12.\n",
      "Combining all monthly data...\n",
      "Data loading and processing complete!\n",
      "6693496    2024-03-07 19:16:55\n",
      "6693497    2024-03-07 19:40:49\n",
      "6697779    2024-03-07 20:37:53\n",
      "6697780    2024-03-07 20:54:56\n",
      "6703121    2024-03-07 21:17:34\n",
      "                   ...        \n",
      "37463263   2024-12-29 23:04:34\n",
      "37463264   2024-12-29 23:08:15\n",
      "37463265   2024-12-29 23:16:15\n",
      "37463266   2024-12-29 23:21:58\n",
      "37463267   2024-12-29 23:10:47\n",
      "Name: pickup_datetime, Length: 30672034, dtype: datetime64[us]\n"
     ]
    }
   ],
   "source": [
    "rides = fetch_batch_raw_data(fetch_data_from, fetch_data_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8776023</th>\n",
       "      <td>2024-03-27 10:17:09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9056155</th>\n",
       "      <td>2024-03-29 19:59:30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9206932</th>\n",
       "      <td>2024-03-30 12:11:27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15501963</th>\n",
       "      <td>2024-05-27 20:03:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16214443</th>\n",
       "      <td>2024-06-02 15:51:11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pickup_datetime  pickup_location_id\n",
       "8776023  2024-03-27 10:17:09                   2\n",
       "9056155  2024-03-29 19:59:30                   2\n",
       "9206932  2024-03-30 12:11:27                   2\n",
       "15501963 2024-05-27 20:03:00                   2\n",
       "16214443 2024-06-02 15:51:11                   2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import transform_raw_data_into_ts_data\n",
    "ts_data = transform_raw_data_into_ts_data(rides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1854580"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data\n",
    "len(ts_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1854580 entries, 0 to 1854579\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   pickup_hour         datetime64[ns]\n",
      " 1   pickup_location_id  int16         \n",
      " 2   rides               int16         \n",
      "dtypes: datetime64[ns](1), int16(2)\n",
      "memory usage: 21.2 MB\n"
     ]
    }
   ],
   "source": [
    "ts_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-06 14:03:03,238 INFO: Initializing external client\n",
      "2025-03-06 14:03:03,239 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-03-06 14:03:04,181 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1214648\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "# connect to the project\n",
    "project = hopsworks.login(\n",
    "    project=config.HOPSWORKS_PROJECT_NAME,\n",
    "    api_key_value=config.HOPSWORKS_API_KEY\n",
    ")\n",
    "\n",
    "# connect to the feature store\n",
    "feature_store = project.get_feature_store()\n",
    "\n",
    "# connect to the feature group\n",
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=config.FEATURE_GROUP_VERSION,\n",
    "    description=\"Time series data at hourly frequency v4\",\n",
    "    primary_key=['pickup_location_id','pickup_hour'],\n",
    "    event_time = ['pickup_hour']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1214648/fs/1202279/fg/1403640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |████████████████████████████████████████████████| Rows 1854580/1854580 | Elapsed Time: 01:22 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: time_series_hourly_feature_group_v4_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1214648/jobs/named/time_series_hourly_feature_group_v4_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('time_series_hourly_feature_group_v4_1_offline_fg_materialization', 'SPARK'),\n",
       " None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group.insert(ts_data, write_options={\"wait_for_job\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
